{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c22e9936",
   "metadata": {},
   "source": [
    "Reading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c188c480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             caption  \\\n",
      "0  Adventures await in every corner of the world....   \n",
      "1         Stepping out in style this weekend. (3640)   \n",
      "2         Stepping out in style this weekend. (5738)   \n",
      "3         Dream big, work hard, stay focused. (8319)   \n",
      "4  Smart budgeting leads to financial freedom. (3...   \n",
      "\n",
      "                                            hashtags  \n",
      "0  #wanderlust #travel #adventure #vacation #explore  \n",
      "1  #ootd #instafashion #fashionblogger #style #fa...  \n",
      "2  #fashion #fashionblogger #instafashion #style ...  \n",
      "3  #mindset #success #inspiration #motivation #goals  \n",
      "4  #investing #money #financialfreedom #finance #...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('social_media_dataset_50000.csv',encoding='latin1')\n",
    "print(df[['caption', 'hashtags']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9be756",
   "metadata": {},
   "source": [
    "Cleaning the Captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "679929d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\maanh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  \n",
    "    tokens = text.split()\n",
    "    tokens = [t for t in tokens if t not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['clean_caption'] = df['caption'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d729c979",
   "metadata": {},
   "source": [
    "Cleaning Hashtag Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6092434d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "def parse_hashtags(raw):\n",
    "    try:\n",
    "        return ast.literal_eval(raw)\n",
    "    except:\n",
    "        return [tag.strip() for tag in raw.split() if tag.startswith('#')]\n",
    "\n",
    "df['hashtags'] = df['hashtags'].apply(parse_hashtags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cf9be3",
   "metadata": {},
   "source": [
    "Vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da3e05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer() \n",
    "Y = mlb.fit_transform(df['hashtags'])  \n",
    "hashtag_labels = mlb.classes_         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f10ae2",
   "metadata": {},
   "source": [
    "Tokenizing,Padding and Splitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b491549",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(df['clean_caption'])\n",
    "X = tokenizer.texts_to_sequences(df['clean_caption'])\n",
    "X_padded = pad_sequences(X, maxlen=50)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_padded, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cb301f",
   "metadata": {},
   "source": [
    "Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b88fc3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 42ms/step - accuracy: 0.1072 - loss: 0.2084 - val_accuracy: 0.1803 - val_loss: 0.0027\n",
      "Epoch 2/5\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 47ms/step - accuracy: 0.1928 - loss: 0.0019 - val_accuracy: 0.1095 - val_loss: 6.6894e-04\n",
      "Epoch 3/5\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 38ms/step - accuracy: 0.1076 - loss: 5.3049e-04 - val_accuracy: 0.1107 - val_loss: 2.7072e-04\n",
      "Epoch 4/5\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 38ms/step - accuracy: 0.1034 - loss: 2.2562e-04 - val_accuracy: 0.1095 - val_loss: 1.3094e-04\n",
      "Epoch 5/5\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 41ms/step - accuracy: 0.1025 - loss: 1.1174e-04 - val_accuracy: 0.1105 - val_loss: 6.8362e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1b3750db350>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "model = Sequential([                                                                                                            \n",
    "    Embedding(input_dim=10000, output_dim=64, input_length=50),                                                                 \n",
    "    LSTM(128),                                                                                                                 \n",
    "    Dense(len(hashtag_labels), activation='sigmoid')                                                                            \n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=5, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a010230",
   "metadata": {},
   "source": [
    "Function to make Predictions,Fun Facts and Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e89bc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_hashtags(caption):\n",
    "    cleaned = clean_text(caption)\n",
    "    seq = tokenizer.texts_to_sequences([cleaned])\n",
    "    padded = pad_sequences(seq, maxlen=50)\n",
    "    pred = model.predict(padded)[0]\n",
    "\n",
    "    threshold = 0.5\n",
    "    result = [hashtag_labels[i] for i, score in enumerate(pred) if score > threshold]\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "123b4974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "social_media_facts = [\n",
    "    \"The first hashtag ever used on Twitter was #barcamp in 2007.\",\n",
    "    \"Instagram was originally called Burbn, focused on whiskey tasting.\",\n",
    "    \"TikTok was the most downloaded app globally in 2021.\",\n",
    "    \"Facebook's blue color scheme was chosen because Mark Zuckerberg is red-green colorblind.\",\n",
    "    \"The egg photo that broke Instagram records in 2019 was posted just to beat Kylie Jennerâ€™s likes.\",\n",
    "    \"LinkedIn is older than Facebook, Twitter, and Instagram â€” it launched in 2003.\",\n",
    "    \"Snapchatâ€™s ghost mascot is named Ghostface Chillah.\",\n",
    "    \"The first YouTube video was titled 'Me at the zoo' and posted in 2005.\",\n",
    "    \"Over 80% of Pinterest users are women.\",\n",
    "    \"Twitter was almost called 'FriendStalker'.\",\n",
    "    \"Instagram hit 1 million users just 2 months after launch.\",\n",
    "    \"Redditâ€™s alien mascot is named Snoo.\",\n",
    "    \"Facebookâ€™s first banner featured Al Pacinoâ€™s face.\",\n",
    "    \"1 in 3 people check social media in the middle of the night.\",\n",
    "    \"Over 10 billion emojis are sent daily â€” ğŸ˜‚ is the most popular.\"\n",
    "]\n",
    "\n",
    "def get_random_fact():\n",
    "    return random.choice(social_media_facts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c99551e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words = [\"happy\", \"great\", \"amazing\", \"love\", \"excited\", \"fun\", \"joy\", \"awesome\", \"good\", \"fantastic\", \"beautiful\", \"smile\",\"best\",\"Smart\"]\n",
    "negative_words = [\"sad\", \"tired\", \"angry\", \"bad\", \"hate\", \"bored\", \"upset\", \"terrible\", \"worst\", \"pain\", \"cry\", \"lonely\"]\n",
    "def simple_sentiment(text):\n",
    "    words = text.lower().split()\n",
    "    pos_count = sum(1 for word in words if word in positive_words)\n",
    "    neg_count = sum(1 for word in words if word in negative_words)\n",
    "\n",
    "    if pos_count > neg_count:\n",
    "        return \"Positive\"\n",
    "    elif neg_count > pos_count:\n",
    "        return \"Negative\"\n",
    "    elif pos_count == 0 and neg_count == 0:\n",
    "        return \"Unknown\"\n",
    "    else:\n",
    "        return \"Neutral\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5b03bd",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8919ef73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step\n",
      "['#catsofinstagram', '#doglife', '#petlovers', '#pets', '#puppylove']\n",
      "ğŸ§  Sentiment: Positive\n",
      "ğŸ’¡ Fun Social Media Fact:\n",
      "Over 10 billion emojis are sent daily â€” ğŸ˜‚ is the most popular.\n"
     ]
    }
   ],
   "source": [
    "#Testing without GUI\n",
    "caption = \"Cuddles with my dog makes me happy\"\n",
    "print(predict_hashtags(caption))\n",
    "sentiment = simple_sentiment(caption)\n",
    "if sentiment == \"Unknown\":\n",
    "    print(\"ğŸ§  Sentiment: Couldnâ€™t detect mood from caption.\")\n",
    "else:\n",
    "    print(\"ğŸ§  Sentiment:\", sentiment)\n",
    "print(\"ğŸ’¡ Fun Social Media Fact:\")\n",
    "print(get_random_fact())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203819e3",
   "metadata": {},
   "source": [
    "GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c24c3338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n"
     ]
    }
   ],
   "source": [
    "# ------------------ GUI Setup ------------------\n",
    "import tkinter as tk\n",
    "from tkinter import ttk, font\n",
    "root = tk.Tk()\n",
    "root.title(\"âœ¨ Hashtag Predictor by Harleen âœ¨\")\n",
    "root.geometry(\"800x550\")\n",
    "root.configure(bg=\"#2E2E4F\")  \n",
    "\n",
    "# Fonts\n",
    "title_font = font.Font(family=\"Poppins\", size=26, weight=\"bold\")\n",
    "subtitle_font = font.Font(family=\"Helvetica\", size=15, weight=\"bold\")\n",
    "text_font = font.Font(family=\"Helvetica\", size=12,weight=\"bold\")\n",
    "output_font = font.Font(family=\"Helvetica\", size=12, weight=\"bold\")\n",
    "\n",
    "# ------------------ Title ------------------\n",
    "title_label = tk.Label(\n",
    "    root,\n",
    "    text=\"âœ¨ Social Media Hashtag Generator âœ¨\",\n",
    "    font=title_font,\n",
    "    bg=\"#2E2E4F\",\n",
    "    fg=\"#FFD369\"\n",
    ")\n",
    "title_label.pack(pady=(15, 10))\n",
    "\n",
    "# ------------------ Input Frame ------------------\n",
    "input_frame = tk.Frame(root, bg=\"#2E2E4F\")\n",
    "input_frame.pack(pady=10)\n",
    "\n",
    "caption_label = tk.Label(\n",
    "    input_frame,\n",
    "    text=\"Enter your caption below ğŸ“¸:\",\n",
    "    font=subtitle_font,\n",
    "    bg=\"#2E2E4F\",\n",
    "    fg=\"#FFD369\",\n",
    "    anchor=\"w\"\n",
    ")\n",
    "caption_label.pack(anchor=\"w\", padx=8)\n",
    "\n",
    "caption_entry = tk.Text(\n",
    "    input_frame,\n",
    "    height=6,\n",
    "    width=100,\n",
    "    font=text_font,\n",
    "    wrap=\"word\",\n",
    "    relief=\"groove\",\n",
    "    borderwidth=2,\n",
    "    bg=\"#393E60\",\n",
    "    fg=\"white\",\n",
    "    insertbackground=\"white\",\n",
    ")\n",
    "caption_entry.pack(padx=20, pady=8)\n",
    "\n",
    "# ------------------ Output Frame ------------------\n",
    "output_frame = tk.Frame(root, bg=\"#2E2E4F\")\n",
    "output_frame.pack(pady=5, fill=\"x\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create output boxes & labels\n",
    "result_label = tk.Label(root,text=\"ğŸ¯ Hashtags:\",font=(\"Helvetica\", 12,\"bold\"),fg=\"white\",bg=\"#393E60\",anchor=\"w\",padx=20,pady=15,bd=2,relief=\"ridge\")\n",
    "result_label.pack(fill=\"x\", padx=8, pady=5)\n",
    "\n",
    "\n",
    "sentiment_label = tk.Label(root, text=\"ğŸ§  Sentiment:\", font=(\"Helvetica\", 12,\"bold\"), fg=\"white\", bg=\"#393E60\", anchor=\"w\", padx=20, pady=15,bd=2,relief=\"ridge\")\n",
    "sentiment_label.pack(fill=\"x\", padx=8, pady=5)\n",
    "\n",
    "fact_label = tk.Label(root, text=\"ğŸ’¡ Fun fact:\", font=(\"Helvetica\", 12,\"bold\"), fg=\"white\", bg=\"#393E60\", anchor=\"w\", padx=20, pady=15,bd=2,relief=\"ridge\")\n",
    "fact_label.pack(fill=\"x\", padx=8, pady=5)\n",
    "\n",
    "# ------------------ Functions ------------------\n",
    "def on_predict():\n",
    "    caption = caption_entry.get(\"1.0\", tk.END).strip()\n",
    "    if caption:\n",
    "        hashtags = predict_hashtags(caption)\n",
    "        result = \", \".join(hashtags) if hashtags else \"No hashtags predicted ğŸ¤·â€â™€ï¸\"\n",
    "        result_label.config(text=f\"ğŸ¯ Hashtags: {result}\")\n",
    "\n",
    "        sentiment = simple_sentiment(caption)\n",
    "        if sentiment == \"Unknown\":\n",
    "            sentiment_label.config(text=\"ğŸ§  Sentiment: Couldnâ€™t detect mood from caption.\")\n",
    "        else:\n",
    "            sentiment_label.config(text=f\"ğŸ§  Sentiment: {sentiment}\")\n",
    "\n",
    "        fact = get_random_fact()\n",
    "        fact_label.config(text=f\"ğŸ’¡ Social Media Fun Fact: {fact}\")\n",
    "        status_bar.config(text=\"âœ… Prediction complete!\")\n",
    "\n",
    "def clear_all():\n",
    "    caption_entry.delete(\"1.0\", tk.END)\n",
    "    result_label.config(text=\"\")\n",
    "    sentiment_label.config(text=\"\")\n",
    "    fact_label.config(text=\"\")\n",
    "    status_bar.config(text=\"ğŸ§¹ Cleared. Ready for a new caption!\")\n",
    "\n",
    "# ------------------ Button Styles ------------------\n",
    "style = ttk.Style()\n",
    "style.theme_use(\"clam\")\n",
    "style.configure(\n",
    "    \"My.TButton\",\n",
    "    foreground=\"black\",\n",
    "    background=\"#FFD369\",\n",
    "    padding=10,\n",
    "    font=(\"Helvetica\", 12, \"bold\")\n",
    ")\n",
    "style.map(\n",
    "    \"My.TButton\",\n",
    "    background=[(\"active\", \"#E1B74A\")]\n",
    ")\n",
    "\n",
    "# ------------------ Buttons ------------------\n",
    "button_frame = tk.Frame(root, bg=\"#2E2E4F\")\n",
    "button_frame.pack(pady=10)\n",
    "\n",
    "predict_btn = ttk.Button(button_frame, text=\"Generate Hashtags\", command=on_predict, style=\"My.TButton\")\n",
    "predict_btn.grid(row=0, column=0, padx=10)\n",
    "\n",
    "clear_btn = ttk.Button(button_frame, text=\"Clear\", command=clear_all, style=\"My.TButton\")\n",
    "clear_btn.grid(row=0, column=1, padx=10)\n",
    "\n",
    "# ------------------ Status Bar ------------------\n",
    "status_bar = tk.Label(\n",
    "    root,\n",
    "    text=\"Ready\",\n",
    "    bd=1,\n",
    "    relief=\"sunken\",\n",
    "    anchor=\"w\",\n",
    "    bg=\"#393E60\",\n",
    "    fg=\"white\",\n",
    "    font=(\"Helvetica\", 10)\n",
    ")\n",
    "status_bar.pack(side=\"bottom\", fill=\"x\")\n",
    "\n",
    "# ------------------ Run App ------------------\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
